---
title: "CANSSI - Reviewer Comments"
output: pdf_document 
bibliography: bibliography.bib
---

Project Title: *Statistical Methods for Daily Mortality and Multiple Environmental Risk Factors*

# General Comments

The Scientific Advisory Committee requests that the full proposal specfically address the following issues

  1. Provide details about the mentoring of the HQP, linking HQP directly to specific mentors. Include details on the mentoring of the student at Laval and how the student will be a full participant in the team.
  
  2. Clarify how the team will function and how team members will interact and collaborate. Describe the roles of the lead investigators in the project and research.
  
  3. Provide more details on how the aims associated with the application are related to the statistical methodology.
  
  4. Briefly describe the available data sets and the confounders present therein.
  
  5. Discuss why you model mortality from asthma, rather than occurrence.
  
  6. Detail the technical challenges to be addressed, provide references to what is already known and clearly state what is to be developed. In your discussion, include the following. $\\$
    A. Provide explicit information on the kinds of constraints you will place on the prior distributions. Provide more extensive references to the literature on shape constrained models.$\\$
    B. Describe the challenges of introducing Bayesian approaches. $\\$
    C. You propose to initiate the models in STAN. Does this mean the research is very straightforward? If not, what are the challenges?


You may wish to consider that the SAC determined that strengths of the proposed project include:

  1. The applied aspect is particularly strong, with a real investment by the partner, Health Canada.
  
  2. The proposed research addresses problems of importance to society.
  
  3. The SAC was particularly enthusiastic about the proposed development of a Bayesian methodology for inference with constrained group-wise additive index models.



\clearpage

# Reviewer One 

The methodological extensions are not compelling, but the application to air pollution epidemiology is novel. 

The inclusion of Health Canada is a major advantage. The interdisciplinary and collaborative nature of the project makes it an excellent training opportunity for early career researchers. The LOI is very clear. 

**Remarks**: This reviewer has positive comments for the LOI, except their first one regarding methodology. 

\vspace{1em}

# Reviewer Two 

A lot of details are left out about the research involved in achieving the three main objectives. 

  1. What research would be needed to construct the new bcAQHI once the new bcGAIM is built and implemented?
  2. Does each health outcome needs its own index? Asthma is very different than other conditions, for instance. 
  3. Future forecasting -- if the AQHI were deemed to be of value, a mother deciding on whether to send her asthmatic child to school would be guided at least in part by that day's AQHI.
  
The cGAIM is by no means a new idea. See Hardle (1993) for $K=1$ and Wang et al (2015) for $K>1$. Special cases were published between 1993 and 2015. The benefits of the bcGAIM are: 

  1. It will quantify uncertainty about $\alpha$ that may show it is not identifiable. If $\alpha$ is identifiable, it may show the relative contributions of one pollutant against another.
  2. The resulting bcGAIM will be able to accommodate higher dimensional $\alpha$'s.
  
The three main research objectives are given short shrift so it is difficult to judge their value. Consider the three research objectives:

  1. The new AQHI would be novel by taking into account of the joint effect of the multiplicity of pollutants, but not knowing how the AQHI will be constructed from the bcGAIM makes it hard to judge the novelty of the work.
  2. An epidemiology study: there are countless studies of the associations between air pollutants and human health, but with less data so the research will be novel. 
  3. The most novel: how the bcAQHI might be used to assess COVID-19 mortality. Why not build a new bcAQHI designed specifically for that purpose? Why use all-causes mortality to estimate $\alpha$ and transform into an index? Ozone is more relevant as a risk index for asthma and PM~2.5~ is or COPD. Why not just publish the pollutant concentrations themselves?
  
A major challenge will be the *big data* issue, since daily mortality counts will be modelled using a semi-parametric model. This would be simplified by designing a different model for each Canadian city. The applicants do not intend to incorporate city-level random city effects to enable strength to be borrowed deficiency. This compromise may be needed for feasibility.

This work could have a significant impact because the proposed collaborative team has a direct pipeline to Health Canada. The LOI could have done better clarifying the links of the Investigators and Collaborators in the proposed project. What is clear is that the LOI/project is designed to provide a pipeline from data to the AQHI. What is not clear is how the collaboration is to be managed. I would like to see is an active group interaction plan, beyond meeting at the SSC. For example,

  1. An effective manager
  2. Subgroups for each component research program would meet regularly -- weekly 
  3. Monthly meeting for the full research group. Students and postdocs might be selected to make presentations. 
  
What is Chebana’s role in the project? Masselot was a PDF at INRS for three years but is not eligible to be an investigator, but has a long list of publications and developed the cGIAM. 

From the information provided, it’s not clear the work is suitable for a postdoctoral fellow, where greater depth and sophistication is expected. The discussion of the bcGAIM is well done, but the three main objectives (and how they relate to each other) should have been better described before diving into methodological details.

**Remarks**: This reviewer's comments are constructive and in-depth. They center around the relationship of the three research objectives, how the collaboration will be managed, and how the bcGAIM will be transformed into an AQHI. 

\vspace{1em}


# Reviewer Three (*)

Three research objectives (developing an improved air quality index, undertaking epidemiological studies, and investigating how air pollution affects daily COVID-19 mortality) are listed, there is little discussion on the 2^nd^ and 3^rd^ objectives. It is not clear how they can be achieved. For instance, naïve case/mortality rate (Objective 3) is subject to undercounting in the numerator and denominator. 

Since the cGAIM is newly proposed and not yet published, it is hard to assess the novelty of the bcGAIM and cGAIM compared to existing methods like the BKMR. Although four methodological advancements of the bcGAIM are listed, those seem like incremental changes of the cGAIM. The potential impact seems marginal since these are incremental changes.

The LOI was not written with clarity. The proposal does not explain how the bcGAIM will help develop an AQHI, so it is not clear how the bcGAIM contributes to achieving the research objectives Also, no specific research plans are presented to achieve Objectives 2 and 3. Also, how the bcGAIM helps with developing an AQHI is not clearly explained.

**Remarks**: This reviewer had a short review that was the anomalous negative review in the .  


\vspace{1em}


# Reviewer Four

A well-written proposal that aims to solve important real-world problems. Their semiparametric and dimension reduction (via index) nature make them useful when one is analyzing data of an unknown/unsure nature. Having high methodology novelty is not the selling point for this proposal. There are no issues in feasibility, except when the dimension of $\alpha$ is high. 

The involvement of Health Canada strengthens the potential impact and merit of this proposal. The links among other collaborators and how will those benefit the project could be better explained. The team has the potential to provide an excellent environment for interdisciplinary training of students. It would be helpful to add the names of the faculty supervisors/collaborators to the mentoring plan. The part for the roles of personnel could be further clarified.

**Remarks**: This reviewer asks for clarification on the mentoring plan and the role of personnel. 

\vspace{1em}


# Reviewer Five 

While the project is motivated by multi-pollutant modeling, it could be strengthed by identifying other applications for this model. Regardless, the three research goals are: 

  1. Develop a multi-pollutant air quality index 
  2. Develop multi-pollutant exposure models for health effects 
  3. Investigate how mixtures of pollutants affects daily COVID-19 mortality.

Bayesian methods provide uncertainty quantification for both $\alpha$ and $s$, which optimization methods do not. The posterior distribution of weights can indicate which directions are well identified, giving the advantage of interpretability. This is an emerging area and has advantages over linear models as positive correlations among exposures complicates interpretation.

Development of a health-outcome model and air-quality index is an additional novelty. However, the proposal should provide more details about how these are related. The following additional areas also need clarification:

  1. What is the relationship between the linear combination of $\alpha$'s goes into $s$ and the AQHI? How will the AQHI indicate not/safety based on $s or $\alpha$? More details on data sources would be helpful (hospital admissions -- asthma, mortality, other conditions)?
  2. The proposal lacks details about the desired shape constraints. There is a significant literature on Bayesian shape constrained modeling (monotonicity). Is this a straightforward to model in Stan, or are there methodological advancements to be made?
  3. The researchers propose developing this model using non-MCMC methods such as INLA. How will this carry over to the Bayesian shape constrained model where $s$, $\alpha$, and $f$ must be estimated? This may provide computational efficiencies in point estimation, but how does it address uncertainty quantification compared to the cGAIM?
  4.The proposal rejects placing a prior on the expansion of $s$, instead placing it directly on s. What priors on function spaces will be used - Gaussian process priors or others? How are the constraints incorporated?
  5. Will this be a joint model for COVID versus non-COVID deaths with a common/different $s$? Will there be common/different linear combinations of exposures? Will this utilize the proposed AQHI? What data is available? Does it provide the necessary information about potential confounders or other covariates? Is individual or aggregated data available? Missing data is an issue with COVID-19 deaths but this is not addressed.
  Other covariates/confounders could potentially include: SES, comorbidities, access to health insurance, housing (nursing homes, dorms, single family, number of inhabitants)
  6. What data is available for each research aims? How will these data sources be integrated?
  7. The proposal mentions developing random effects in $s$. What do these capture and what is the motivation -- spatial random effects, treating the weights as random effects?
  
Some aims use Stan, while others propose to develop INLA-like methods. The methodology draws upon existing methods so there is a is a high probability for success. Even if no novel methodology is developed, there is a high probability of advancement in air pollution research. There is potential for advancement in Bayesian shape constrained modeling (particularly priors and representation) and efficient inference through INLA. Development of multi-pollutant models that are robust to the correlation of mixtures of exposures and interpretable, and an associated AQHI would have broad impact for research and the public. 

Potential weaknesses in the current proposal are that methodological details are sparse -- is this a relatively routine model to fit in Stan or are there methodological advancements there? What are the challenges of extending single pollutant models to the multi-pollutant models using INLA like approximations beyond scaling in dimension to say 3 or higher with lags?
  
Highlighting previous collaborations among the team members would strengthen the proposal. Is there is a single senior lead investigator? Who will be mentors for the PDF and PhD students (beyond the PDF)?. There are no faculty listed as investigators at the University of Laval -- the proposal could be strengthened by (briefly) discussing who is leading the team, the frequency of team meetings, and the roles of the lead investigators. The objectives and aims are well laid out. More details about advancements, challenges, and data sources for each aim would strengthen the proposal.

**Remarks**: This is a very thorough review. It raises a number of issues, beginning with the role of the lead investigators and the supervisory structure of the project. It also asks for a number of methodological clarifications, some of which were also raised by other reviewers. These include: 

  - How is the bcGAIM related to the AQHI (and safe/not safe indicator)? Are the shape constraints easy to implement in Stan? Does the INLA-like implementation also provide uncertainty quantification? What priors will be used on $s$? What data is available for each research aim; how will they be integrated? What is the motivation for developing random effects on $s$? More details are needed on the COVID aim.
  
Finally, the reviewer asks for more details on the challenges of extending from single to multi-pollutant models using INLA-like approximations (beyond scaling in dimension to 3 or higher with lags).



\clearpage

# Details on Shape Constraints

We seek simple and interpretable shape constraining priors that non-statistical experts can use. Our project team is interdisciplinary and the bcGAIM multi-pollutant model will be used and interpreted by people with many different backgrounds. For example, consider a prior $\pi(\phi)$ on $s$ that encourages (for example) monotonicity. Viewing the bcGAIM with $s$ monotonic as nested within the bcGAIM with $s$ unconstrained, we want $\phi$ to control how strongly $s$ is encouraged towards the nested model. Moreover, how strongly $\pi(\phi)$ encourages monotonicity should be easy to communicate visually so that we can elicit prior information from non-statistical experts and better communicate the modeling results to them. 

We will develop priors for a number of Gaussian processes, such as random walks. Priors can have subtle negative effects on the posterior, which cam be very difficult to discern in complex hierarchical models and high dimensional settings. For example, a truncated multivariate normal (tMVN) prior can induce monotonicity if placed on the coefficients of a basis expansion of $s$ [@maatouk2017gaussian]. However, a tMVN prior subject to linear constraints places neglible mass in near-flat regions of $s$ in high-dimensional settings. This is remedied in @zhou2020truncated, who introduce a multiplicative scale parameter on each coordinate of the tMVN, and using the half-Cauchy as a shrinkage prior on these parameters. We will perform iterative development of our priors, conducting simulation studies to verify that they do not introduce undesirable side effects. 

There is a vast literature on shape-constrained inference. We briefly highlight some frequentist papers below. In an influential paper, @ramsay1988monotone proposes an unconstrained inference method for monotone functions, and @meyer2008inference extends these results to additional shape constraints. @mammen1999smoothing describes a correspondence between fitting a constrained function and fitting then projecting an unconstrained function onto a constrained space; we discuss a Bayesian projection method by @lin2014bayesian below. Considering constrained inference, @sysoev2019smoothed use a penalized likelihood to enforce monotonicity while maintaining smoothness properties, while @leitenstorfer2007generalized constrains the coefficients of the basis expansion to enforce montonicity. Finally, there is an emerging branch of machine learning literature focusing on shape constrained inference, which shares our project's goal of improving model interpretability in big data settings but is somewhat orthogonal to Bayesian inference methods we will be using [@sill1998monotonic; @gupta2016monotonic; @wehenkel2019unconstrained].

We now turn to Bayesian shape-constrained inference for Gaussian processes. The distribution of a constrained Gaussian process is no longer a Gaussian process. However, the derivative of a Gaussian process is; @riihimaki2010gaussian use this to enforce monotonicity. They employ a data augmentation scheme where the derivatives are required to be positive at the virtual locations. @agrell2019gaussian and @wang2016estimating find that a relatively small number of virtual observations are needed to to ensure the shape constraint holds globally with high probability. However, we have found that the effect of air pollution can substantially deviate from monotonicity [@kamal2020trends]. Also, our air pollution data sets have over 6,000 daily observations per region, and adding more virtual observations may not be computationally feasible. Therefore, data augmentation is not optimal for the goals of this project.

Another approach is to approximate the Gaussian process with a basis expansion and constrain the coefficients of that expansion, but it can be difficult to relate the priors of these coefficients to the shape of $s$ [@lopez2018finite; @maatouk2017gaussian]. @lin2014bayesian introduce a method that projects unconstrained Gaussian processes onto a shape-constrained space. However, this approach has two limitations. The first is that it cannot conduct inference on covariance parameters, as those posterior distributions are affected by the projection. The second is that the projection often produces non-smooth sample paths, which reduces interpretability [@golchi2015monotone]. Both limitaions make it undesirable for this project. In yet another approach, @lenk2017bayesian assume the q^th^ derivative of $s$ are squares of Gaussian processes, where $q = 1$ for monotonicity and $q = 2$ for convexity. They place priors on the coefficients of a Karhunen-Loeve expansion, which are not particularly interpretable.

Instead of placing a prior on $s$, we could place priors on the coefficients of a basis expansion of $s$. The first question this raises is which basis expansion to use. @zhou2020truncated list Bernstein polynomials, regression splines, penalized spines, cumulative distribution functions, and restricted splines as being used in the literature. The next question is how to set interpretable priors. For example, the widely cited @shively2009bayesian uses a mixture of constrained normals $N^{*}(0,c\sigma^{2}\Sigma)$ as the prior on the coefficients of a spline regression to encourage monotonicity. However, this prior can be difficult to interpret -- the constrained normal $N^{*}$ can be hard to explain to non-statistical experts, and the scale parameter $c$ has to be tuned by the user. The interpretation challenges become more severe as $\Sigma$ becomes higher-dimensional.

We would like the achieve the level of interpretability seen in @burkner2020modelling, who propose a Bayesian model to estimate ordinal predictors with monotonic effects. They employ a simplex parameter $\zeta$ to model normalized differences between categories, and a scale parameter $b$. The prior on $b$ expresses prior knowledge on the average differences between adjacent categories, while the prior on $\zeta$ expresses prior knowledge on individual differences between adjacent categories. The authors suggest using an $N(0,\sigma)$ prior on $b$ and a $Dirichlet(\alpha)$ prior on $\zeta$, since $\sigma$ and $\alpha$ would then penalize the average and individual differences between adjacent categories. Not only are $\zeta$ and $b$ interpretable, but so are the prior parameters $\sigma$ and $\alpha$. 


<!-- 
In @shively2009bayesian, the authors note that monotonicity may be violated in a model because of measurement error or omitted variables. They first consider a modified version of @ramsay1988monotone's unconstrained estimation framework that allows for unconstrained monotonic estimation, and embed it in a hierarchical framework. They then consider a Bayesian regression spline model, where they use a mixture of constrained normal distributions as a prior on the regression coefficients $\beta$ to encourage monotonicity. Their construction moves probability mass from regions that do not ensure monotonicity to boundaries of regions that do; placing mass on the boundaries ensures the model can estimate near-flat regions of the monotonic function. The $\beta$ is $N^{*}(0,c\sigma^{2}\Sigma)$, where $N^{*}$ is the constrained normal distribution defined above. The parameter $c$ is a postive scale factor that must be specified by the user. As creative as this prior is, it has two limitations -- the constrained prior $N^{*}$ may be hard to understand, and it may be difficult to choose an appropriate $c$.
-->

<!--
In @brezger2008monotonic, the authors use prior distributions to enforce monotonicity on Bayesian P-splines. We will also be using a prior-based approach but will be modeling the effect of air pollution using random walks. We will also be seeking more interpretable priors. 
-->

\clearpage

# Details on cGAIM and bcGAIM

The cGAIM uses an iterative two-step optimization scheme. In the first step $\alpha$ is updated using a quadratic program, while in the second step $s$ is updated using the methodology from @pya2015shape. In the cGAIM, any linear constraint can be placed on $\alpha$. For example, it can be constrained to have non-negative components that sum to one, so that it is a vector of weights. Once estimated, these weights give the relative contribution of each component to the outcome of interest. The cGAIM can also constrain the shape of $s$ by requiring it to, for example, be monotonic or convex. 

The cGAIM considers both constraints and groupwise additive index terms, while much of the existing literature only considers groupwise additive terms. For example, @hardle1993optimal focus on a single index and minimize a least-squares criteria where $s$ is replaced by its leave-one-out Nadaraya-Watson estimator, and a trimmed version of this estimator is used to jointly choose its bandwidth parameter and estimate $\alpha$. For several indices, @wang2015estimation minimize a least-sqaures via a two-stage estimation procedure for models similar to those seen in (1). They derive large-sample properties of the least-squares estimator, and propose a penalized least-squares estimator for sparse high-dimensional settings. A few other papers propose alternative objective functions to the one of Wang, more or less based on least-squares [@li2010groupwise; @guo2015groupwise; @wang2017robust]. However, none of these papers consider constrainted estimation. 

One paper that considers constraints is @xia2006cumulative where the authors constrain $s$ to be monotonic and the components of $\alpha$ to be non-decreasing. Another is @fawzi2016structured, where the authors constrain the components of $\alpha$ to be non-negative and sum to one but do not constrain $s$. In comparison, the cGAIM allows for any linear constraint on $\alpha$ and different shape constraints on $s$ including montonicity, convexity, and concavity [@pierre2020aim]. Finally, while there are R packages, such as $\texttt{scam}$ and $\texttt{cgam}$ that faciliate shape-constrained inference, they do not estimate $\alpha$ [@pya2015shape; @liao2019cgam]. The cGAIM considers shape constrained inference of $s$ while estimating $\alpha$ under a variety of possible constraints on $\alpha$ and $s$. In this spirit, the bcGAIM will allow users to specify a variety of constraints on $\alpha$ and $s$ simultaneously, while reporting posterior distributions that communicate estimation uncertainty for both.

The bcGAIM will initially be implemented in Stan, a statistical modeling language that performs optimization using Hamiltonian Monte Carlo [@carpenter2017stan]. With Stan performing the optimization, the initial task is to develop priors that enforce the constraints seen in the cGAIM. As a simple example, setting a Dirichlet prior on $\alpha$ constrains it to be a vector of weights [@betancourt2012cruising]. Compared to the cGAIM, the bcGAIM provides two main statistical benefits. The first is that it provides credible intervals for $\alpha$, while the cGAIM does not provide confidence intervals for $\alpha$. Quantifying the uncertainty of the estimates for $\alpha$ is important for a very important scientific question in the multi-pollutant model -- can the bcGAIM attribute health effects to specific pollutants? Narrow credible intervals would indicate that it can, while wide credible intervals indicate that it can identify health effects but not attribute them to specific pollutants. Either result would be a significant contribution to the development of multiple pollutant models, as it would provide evidence if the health effects of air pollution can be associated to particular pollutants through $\alpha$ or only to a mixture through $s$. The second advantage is that the bcGAIM can identify and address multi-modality in the posterior of $\alpha$. If $\alpha$ is multimodal under an uniformative prior, one can use relevant scientific knowledge to place stronger priors on $\alpha$. In comparison, the cGAIM only provides a point estimate for $\alpha$ and cannot detect multi-modality.

The bcGAIM has many more potential applications beyond the bcGAIM. The question to ask is if the target for inference is a mixture, such that producing a single measure of the effect of the mixture answers the research question at hand. Other variables that could be suitably grouped to improve interpretability include socio-economic or economic variables, weather variables, and lags of the same variable [@xia2006cumulative]. **TODO**: ask for other applications? 

Following its implementation in Stan, the bcGAIM will be estimated using non-MCMC inference methods, similar to Iterated Nested Laplace Approximation (INLA) [@rue2009approximate]. These methods provide computational and ease-of-use and benefits, and will expand the types of problems and number of users who can make use of the bcGAIM methodology. We will also explore using different response distributions for the multi-pollutant model. The log-linear Poisson model is typically used [@dominici2002use; @liu2019ambient], while the case crossover has seen increased attention in recent years [@wei2019short; @stringer2018cco]. It can be viewed as a conditional Poisson model, obtained by stratifying by subject and conditioning on the number of events occurring in an observation period.


\clearpage 

# The Available Data Sets

Air pollution and mortality/morbidity data sets for 25 cities across Canada from Health Canada. Air pollution and mortality/morbidity data sets for ... cities in Quebec from ... COVID-19 case and mortality data for regions across Canada. 

Environmental data that may confound the effect of air pollution, such as temperature and humidity, is publicly available. For COVID-19, the potential confounders and other relevant variables are still being actively investigated. Potential confounders include socio-economic status, race, population density, and occupation.


\clearpage

# How Are The Aims Associated With The Statistical Methodology? 

This project has three research aims: 

  1. Develop a multi-pollutant air quality health index (AQHI).
  2. Develop multi-pollutant exposure models for health effects. 
  3. Investigate how mixtures of pollutants affects daily COVID-19 mortality.
  
We address how the proposed statistical methodology will be used in each research aim.

---

The first research aim is to develop a multi-pollutant air quality index. We will do so by developing the bcGAIM, the multi-pollutant model discussed above. With a Poisson response distribution and the response variable being the appropriate health outcome, the bcGAIM will output a relative risk for every combination of (measured or forecasted) pollutant values input into the model. The AQHI will take the relative risks as inputs and output warnings, based on cutpoints for the relative risk. Forecasted pollutant values will be provided by Environment Canada.

The motivating research question in developing the bcGAIM is the air quality index. The inquiry into shape-constrained priors is motivated by the air pollution application. A priori, we may believe that increasing levels of an multi-pollutant mixture is associated with worse health outcomes. There are also extreme air pollution events, such as forests fires, such that we may believe that rapidly increasing pollutant levels leads to even worse health outcomes. Thus, we may wish to constrain $s$ to be  negative  (**CITE**) To express this in a Bayesian framework, we seek to develop interpretable priors that do so. This is the motivating problem for this proposal. The two following problems are further applications of the bcGAIM of interest to our broader research goals.

---

The second research aim is to develop multi-pollutant exposure models for health effects. This will be pursued with colloborators, using the bcGAIM to model their outcomes of interest. **TODO**: Add a few more sentences -- potential (epidemiological) outcomes of interest, motivations behind these applications, and the applicability of the bcGAIM to them. Perhaps with other investigators or collaborators? 

--- 

The third research aim is to investigate how mixtures of air pollutants affect daily COVID-19 mortality. This is an application of the bcGAIM, where the response variable is COVID-19 mortality and the argument of $s$ is a linear combination of polutants. The multi-pollutant model includes day-of-the-week effects and seasonal terms, as well as smooth functions of confounders such as time and temperature. The research into relevant regression variables and confounders for COVID-19 is ongoing, as are the research questions of interest. COVID-19 datasets are available at the national and state/provincial levels. Canada, the United States, and a number of European countries maintain public COVID-19 data portals, while the World Health Organization provides data for a number of other countries (such as Russian, Brazil, Turkey, and Romania). 

We will confine our efforts to the Canadian data, for which we have non-COVID-19 mortality data courtesy of Health Canada. In Canada, COVID-19 data is released by the provinces, and differs in its resolution and the variables available. We briefly describe the available data below: 

  1. PEI provides case data (positive and negative tests), and gives the gender distribution and age distribution of confirmed cases. As of September 27^th^, there have been no hospitalizations or deaths. 
  2. Newfoundland gives cumulative case data, cumulative number of people tested, and cumulative cases by age, all by regional health authority. They also provide cumulative cases for the other Canadian provinces and territories. 
  3. Nova Scotia provides cumulative case data, total number of cases by Nova Scotia Health Authority zone, and provides the age distribution and gender distribution of the cumulative cases. 
  4. 
  
The publicly available data has some obvious disadvantages. 
  
\clearpage

# Extending This to an "INLA-like" Methodology

The major benefit of the bcGAIM model is that is provides uncertainty bounds on the weights of the multi-pollutant mixture. In addition to the Stan implementation, we also wish to develop a non-MCMC inference implementation, similar to those used in INLA. For the INLA approximation to work, the conditional posterior of $s$ and $\alpha$ must be able to be approximated by a Gaussian distribution. However, the posterior distributions of $\alpha$ is likely to be multi-modal. Different values of $\alpha$ will likely evaluate to the same value $\alpha \cdot z$, such that significant methodological innovations may be required to extend the INLA approximations to this setting.  

The multi-modal posterior of $\alpha$ is a property of the model, While Stan will return a posterior distribution for $\alpha$, discerning between the possible modes of $\alpha$ will be a challenging problem even when conducting inference in Stan. If expert knowledge suggests one mode is preferable to the others, the prior distribution on $\alpha$ can encode this information. If there is no such prior knowledge, the posterior of $\alpha$ will be correctly capturing the uncertainty regarding its mode. This is a desirable feature of Bayesian inference that will help us, for example, encode this information in the AQHI. 

Returning to the INLA approximation, another reason to initially implement the multi-pollutant model in Stan is that we can begin by applying the Laplace approximation to the parameters on the multi-pollutant for which established methodology exists. In the case of Latent Gaussian models, the authors of @margossian2020hamiltonian embed the Laplace approximation within Stan's Hamiltonian Monte Carlo (HMC) sampler. With the Latent Gaussian model having latent Gaussian parameter $\theta$ and hyper-parameter $\phi$, 

$$
\begin{aligned}
  y & \sim \pi(y | \theta,\phi), \\
  \theta & \sim N(0,K(\phi)),  \\
  \phi & \sim \pi(\phi)
\end{aligned}
$$
the model marginalizes out the latent Gaussian parameter $\theta$. The posterior distribution are given by,

$$
\begin{aligned}
  \pi( \theta, \phi | y ) \propto \pi(y | \theta, \phi) \pi(\theta | \phi) \pi(\phi)
\end{aligned}
$$
However, applying HMC to Latent Gaussian models is often complicated by pathologies in the posterior geometry introduced by $\theta$. In addition to its computational benefits, when applied to $\pi(\theta | \phi,y)$ the Laplace approximation can improve the posterior geometry and thus the performance of HMC on the remaining parameters. Applying the Laplace approximation to $\pi(\theta | \phi,y)$ gives, 

$$
\begin{aligned}
  \phi( \theta | \phi, y ) &= \pi_{G}( \theta | \phi, y ), \\
      &= N(\theta^{*}, \Sigma^{*}),
\end{aligned}
$$
where $\theta^{*}$ matches the mode and $\Sigma^{*}$ the curvature of $\pi(\theta|\phi,y)$ at $\theta^{*}$. Then, the marginal posterior of $\phi$ is, 

$$
\begin{aligned}
  \pi(\phi|y) &= \pi_{G}(\phi|y), \\
              &= \pi(\phi) \frac{ \pi(\theta^{*}|\phi) \pi(y|\theta^{*},\phi) }{ \pi_{G}(\theta^{*}|\phi,y) }.
\end{aligned}
$$
INLA performs approximate inference on $\phi$ by characterizing $\phi$ around its mode - $\theta^{*}$ is the mode and $\Sigma^{*}$ matches the curvature at the mode. Note that if the likelihood is log-concave and Gaussian priors are used, $\pi(\theta|\phi,y)$ will be unimodal, making it amenable to the Laplace approximation. With $\theta$ marginalized out, the target for (approximate) inference in Stan is now $\pi_{G}(y|\phi)$. In @margossian2020hamiltonian, the authors show that embedding the Laplace approximation in HMC performs well for log-concave likelihoods. They comment that the error introduced by the approximation is not well-studied for non-concave likelihoods, which can be modelled in Stan. It is this flexibility that makes initially implementing the bcGAIM model in Stan so attractive.

Recall that Stan performs exact inference on the posterior distribution of model parameters. As such, it is uniquely suited to characterizing the estimation error introduced by approximations that we may use. This allows us to fully characterize the estimation error of each component of our proposed approximation as it is introduced into the model, which we could not do if we implemented the approximate inference algorithm from scratch. While it is difficult to speculate on the direction these approximations may take, some initial ideas are presented below. 

The first consideration is that the Gaussian approximation above separates the parameter space in terms of covariance parameters $\phi$ and latent Gaussian observations $\theta$. This is not likely to profitable with the bcGAIM, which we recall is given by, 
$$
\begin{aligned}
  Y_{t} | \lambda_{t} &= D(\lambda_{t}, \tau), \\
  g(\lambda_{t}) &= X_{t}\beta + s( \alpha^{T} Z_{t}) + f_{1}(W_{1,t}) + \ldots + f_{K}(W_{K,t}),
\end{aligned}
$$
For simplicity, assume a normal response distribution and that $s, f_{1}, \ldots, f_{K}$ are 1^st^ or 2^nd^ order random walks (and thus also normally distributed). Conditional on $\alpha$, $\alpha^{T}Z_{t}$ is known. The Gaussian approximation above views model parameters in terms of $\phi$ and $\theta$, and considers the densities $\pi( \eta | Y, \theta)$, $\pi( \theta | Y)$, and $\pi(\eta | Y) = \int \pi(\eta | Y,\theta) \pi(\theta | Y) d\theta$ (the last one numerically). In @margossian2020hamiltonian, the authors estimate $\pi(\theta|\phi,y) = \pi_{G}(\eta|\theta,y)$ with the Laplace approximation and estimate $\pi(\theta|y)$ with HMC. 

We may wish to view the model parameters in terms of $\phi$, $\theta$, and $\alpha$. Then, we would consider the densities $\pi(\eta | Y, \theta, \alpha)$, $\pi( \theta | Y, \alpha )$, $\pi(\alpha | Y)$, and $\pi(\eta | Y) = \int \pi(\eta | Y, \theta, \alpha) \pi( \theta | Y, \alpha ) \pi(\alpha | Y) d\theta d\alpha$ (the last one numerically). Then, for example, we could apply a Laplace approximation to $\pi( \theta | Y, \alpha )$ and $\pi( \theta | Y, \alpha )$, while having $\pi(\alpha | Y)$ be estimated in Stan using HMC. This would establish a baseline for the approximate inference within Stan, and leave open the question of performing approximate inference on $\pi(\alpha|Y)$. This approximation method can also be prototyped in Stan, it is more challenging because of the multi-modality inherent in the posterior distribution of $\alpha$. Potential approaches are to use a non-Gaussian distribution, to ..., or to ... .

Implementing these approximations will be important for the later applications of the multi-pollutant model, where we aim to build a hierarchical model to produce national estimates of air quality. Using 20 years of air pollution and mortality data for one region (a city or census division) gives over 6,000 observations per region. There is data for at least 25 regions across Canada, making this a daunting computational task unless approximations like those discussed above are used. Once an approximation method is developed in Stan, we will begin a standalone implentation that will be released as an R package, like the extension to the INLA methodology seen in @stringer2020approximate.

## For the main research proposal

In addition to implementing the bcGAIM in Stan, we will develop non-MCMC inference methods similar in spirit to INLA. The Latent Gaussian approximation in INLA separates the parameter space into covariance parameters $\theta$ and linear predictors $\eta = (\beta, \theta, f)$, and considers $\pi( \eta | Y, \theta)$, $\pi( \theta | Y)$, and $\pi(\eta | Y) = \int \pi(\eta | Y, \theta) \pi(\theta | Y) d\theta$ (the last one numerically). INLA performs approximate inference on $\theta$ by estimating $\phi( \theta | Y, \phi )$ with a normal distribution with mean $\theta^{*}$ and variance $\Sigma^{*}$. If the likelihood is log-concave and Gaussian priors are used, $\pi( \theta | Y, \phi )$ is unimodal and is well-approximated by the Laplace approximation. In @margossian2020hamiltonian, the authors estimate $\pi( \theta | Y, \phi)$ with the Laplace approximation and $\pi( \theta | T)$ with Hamiltonian Monte Carlo. They find that this performs well for their examples, both of which have log-concave likelihoods.

Let us translate this reasoning to the bcGAIM, which has link function $g(\lambda_{t}) = X^{t}\beta + s( \alpha^{T} Z_{t}) + f_{1}(W_{1,t}) + \ldots + f_{K}(W_{K,t})$. Note that conditional on $\alpha$, $\alpha^{T}Z_{t}$ is known. Thus, we can simplify the estimation problem by considering parameters $\phi$, $\theta$, and $\alpha$ and estimating $\pi( \eta | Y, \theta, \alpha)$, $\pi( \alpha | Y, \theta )$, $\pi(\theta | Y)$, and $\pi(\eta | Y) = \int \pi(\eta | Y, \theta, \alpha) \pi( \alpha | Y, \theta ) \pi( \theta | Y) d\theta d\alpha$ (the last one numerically). The first and third densities in the integrand, $\pi(\eta | Y, \theta, \alpha)$ and $\pi( \theta | Y)$ are well-suited to the Laplace approximation while $\pi(\alpha | Y,\theta )$ can be estimated using HMC. Introducing two Laplace approximations will lessen the computational burden, and enable us to fit a hierarchical bcGAIM model to air pollution data. This will allow us to produce national estimates of air quality while fitting the bcGAIM to over 25 regions across Canada, each with over 6,000 daily observations, an otherwise daunting computational task. 

We will also introduce an approximation for $\pi( \alpha| \theta,Y )$. However, $\pi( \alpha | \theta,Y )$ we must first investigate if it is well-approximated by Laplace approximation. If it is not, we will have to implement a different approximation method for it. Stan performs exact inference, and is uniquely suited to characterizing the bias introduced by any approximation of $\pi( \alpha | Y,\theta )$. The ability to incrementally implement approximations and characterize their performance makes Stan the ideal tool for developing the bcGAIM and its approximations. Once the three densities are approximated in Stan, we will implement a standalone version outside of Stan that will be released as in R package.



\clearpage

# References

<div id="refs"></div>
